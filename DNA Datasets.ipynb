{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b5ea21-9c57-4ad2-acf9-b383667d0268",
   "metadata": {},
   "source": [
    "# DNA Dataset Generator\n",
    "\n",
    "This notebook parses fastq files and stores corresponding DNA sequence base calls and quality scores in shelve dictionaries for easy use. This notebook was designed for a (currently) private dataset, but can be tweaked as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ce3e95-e36f-46b7-bf30-ab50d16223b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import shelve\n",
    "import time\n",
    "\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8557b271-14d1-470f-858b-cd273bf83a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_DIR = pathlib.Path(\"./Nachusa\")\n",
    "WRITE_DIR = pathlib.Path(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d833e3dc-ebfa-4d8a-9195-a5d3edc46673",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTQ_REGEX = r\"(?<=0000_AG_)(\\d{4})-(\\d{2})-(\\d{2})(?=.fastq)\"\n",
    "BASE_CALL_MAP = { v:i for i, v in enumerate(\"NACGT\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c023cc-3263-4bb9-a950-2f0b7cb06a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastqFile:\n",
    "    def __init__(self, path, season):\n",
    "        self.path = str(path)\n",
    "        self.season = season\n",
    "        self.samples = None\n",
    "        \n",
    "    def extract_sequence_id_info(self, sequence_id):\n",
    "        info = {}\n",
    "        \n",
    "        # Split up the sequence ID information\n",
    "        left, right = sequence_id.split(' ')\n",
    "        left = left[1:].split(':') # Remove @ char\n",
    "        right = right.split(':')\n",
    "        \n",
    "        info[\"instrument\"] = left[0]\n",
    "        info[\"run_number\"] = int(left[1])\n",
    "        info[\"flowcell_id\"] = left[2]\n",
    "        info[\"lane\"] = int(left[3])\n",
    "        info[\"tile\"] = int(left[4])\n",
    "        info[\"pos\"] = map(int, left[5:])\n",
    "        \n",
    "        info[\"read_type\"] = int(right[0])\n",
    "        info[\"is_filtered\"] = right[1] == 'Y'\n",
    "        info[\"control_number\"] = int(right[2])\n",
    "        info[\"sequence_index\"] = right[3]\n",
    "        \n",
    "        return info\n",
    "        \n",
    "    def load(self, shuffle=False, include_read_info=False):\n",
    "        self.samples = []\n",
    "        with open(self.path) as f:\n",
    "            sequence_id = f.readline()\n",
    "            while sequence_id:\n",
    "                # Read the sample\n",
    "                if include_read_info:\n",
    "                    sample = self.extract_sequence_id_info(sequence_id.strip())\n",
    "                else:\n",
    "                    sample = {}\n",
    "                sample[\"base_calls\"] = f.readline().strip()\n",
    "                f.readline() # +\n",
    "                sample[\"quality_scores\"] = f.readline().strip()\n",
    "                sample[\"length\"] = len(sample[\"base_calls\"])\n",
    "                self.samples.append(sample)\n",
    "\n",
    "                # Next file\n",
    "                sequence_id = f.readline()\n",
    "    \n",
    "    def free(self):\n",
    "        self.samples = None\n",
    "        \n",
    "    def encode_sample(self, index):\n",
    "        return np.array([\n",
    "            [BASE_CALL_MAP[token] for token in self.samples[index][\"base_calls\"]],\n",
    "            [(ord(token) - 33) for token in self.samples[index][\"quality_scores\"]]\n",
    "        ])\n",
    "    \n",
    "    def encode_gen(self, indices):\n",
    "        for i in indices:\n",
    "            yield self.encode_sample(i)\n",
    "        \n",
    "    def encode(self, shuffle=False, split=False):\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(len(self.samples))\n",
    "        else:\n",
    "            indices = np.arange(0, len(self.samples))\n",
    "        \n",
    "        if split:\n",
    "            if type(split) in (int, float):\n",
    "                split = [split]\n",
    "            split = list(map(lambda x: int(x*len(indices)), [0] + split + [1]))\n",
    "            return [self.encode_gen(indices[split[i-1]:split[i]]) for i in range(1, len(split))]\n",
    "        return self.encode_gen(indices)\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Total training samples:\", self.train.index)\n",
    "        print(\"Total testing samples:\", self.test.index)\n",
    "            \n",
    "    def __enter__(self):\n",
    "        self.load()\n",
    "        \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.free()\n",
    "                \n",
    "    def __str__(self):\n",
    "        return self.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279880c6-a697-4ff9-958c-dda59cf92288",
   "metadata": {},
   "source": [
    "## Find Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37e90cb-c864-4ce8-8587-6bd199800da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fall', 'Spring']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons = [d for d in os.listdir(READ_DIR) if not d.startswith('.')]\n",
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba04630-a50c-4035-9a43-5aa0c2e3d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nachusa/Fall/0000_AG_2016-10-07.fastq\n",
      "Nachusa/Fall/0000_AG_2017-10-13.fastq\n",
      "Nachusa/Spring/0000_AG_2020-05-11.fastq\n",
      "Nachusa/Spring/0000_AG_2018-04-23.fastq\n",
      "Nachusa/Spring/0000_AG_2017-05-02.fastq\n",
      "Nachusa/Spring/0000_AG_2016-04-22.fastq\n",
      "Nachusa/Spring/0000_AG_2019-05-14.fastq\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "for season in seasons:\n",
    "    for filename in os.listdir(READ_DIR/season):\n",
    "        if not filename.endswith(\".fastq\"):\n",
    "            continue\n",
    "        files.append(FastqFile(READ_DIR/season/filename, season))\n",
    "        print(files[-1].path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415bdc5-c946-4c73-a06b-17f40d0c92df",
   "metadata": {},
   "source": [
    "## Dump All by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cdc02d1-477e-45c6-bb9d-92afba9d5d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7; File: Nachusa/Spring/0000_AG_2019-05-14.fastq completed"
     ]
    }
   ],
   "source": [
    "for progress, file in enumerate(files):\n",
    "    date = re.search(FASTQ_REGEX, file.path)[0]\n",
    "    store = shelve.open(str(WRITE_DIR/f\"samples/{file.season.lower()}_{date}\"))\n",
    "    with file:\n",
    "        samples = file.encode(shuffle=True)\n",
    "        for i, sample in enumerate(samples):\n",
    "            store[str(i)] = sample\n",
    "    store.close()\n",
    "    print(f\"\\r{progress+1}/{len(files)}; File: {file.path} completed\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a7e8d-2231-4ac6-9be9-cabe7ab7b36b",
   "metadata": {},
   "source": [
    "### Split Files Into Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8187ab74-8740-4946-94a2-1b1e9bfea352",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8430c0ae-33d4-4541-887e-2076da8489ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fall_2016-10-07',\n",
       " 'fall_2017-10-13',\n",
       " 'spring_2016-04-22',\n",
       " 'spring_2017-05-02',\n",
       " 'spring_2018-04-23',\n",
       " 'spring_2019-05-14',\n",
       " 'spring_2020-05-11'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = set([os.path.splitext(f)[0] for f in os.listdir(WRITE_DIR/\"samples\") if re.match(r'.*\\.(?:db|dat)$', f)])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d93f10dc-ce1b-4678-91a8-17998cba1855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7; File: Nachusa/Spring/0000_AG_2019-05-14.fastq completed"
     ]
    }
   ],
   "source": [
    "for progress, name in enumerate(files):\n",
    "    store = shelve.open(str(WRITE_DIR/\"samples\"/name))\n",
    "    train = shelve.open(str(WRITE_DIR/f\"{name}_train\"))\n",
    "    test = shelve.open(str(WRITE_DIR/f\"{name}_test\"))\n",
    "    indices = np.random.permutation(len(store))\n",
    "    partition = int(len(store)*(1 - test_split))\n",
    "    for i, index in enumerate(indices[:partition]):\n",
    "        train[str(i)] = store[str(index)]\n",
    "    for i, index in enumerate(indices[partition:]):\n",
    "        test[str(i)] = store[str(index)]\n",
    "    store.close()\n",
    "    train.close()\n",
    "    test.close()\n",
    "    print(f\"\\r{progress+1}/{len(files)}; File: {file.path} completed\", end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
